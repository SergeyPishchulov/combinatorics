{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from bitarray import bitarray, bits2bytes\n",
    "import random\n",
    "random.seed(202)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Jack_London_-_The_Sea_Wolf_ascii.txt', 'r') as file:\n",
    "    text = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8217, 122)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('’'), ord('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.log(10000, 2)\n",
    "2**14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 10000]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BYTE_ORDER = 'big'\n",
    "\n",
    "class ListByte:\n",
    "    def encode(l):\n",
    "        return b''.join([(int(x)).to_bytes(2, byteorder=BYTE_ORDER) for x in l])\n",
    "    \n",
    "    def decode(bs):\n",
    "        return [int.from_bytes(bs[2*i:2*(i+1)], byteorder=BYTE_ORDER)\n",
    "                 for i in range(len(bs)//2)]\n",
    "            \n",
    "ListByte.decode(ListByte.encode([1,2,3, 10000]))\n",
    "\n",
    "# int.from_bytes((2).to_bytes(2, byteorder='big'), byteorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "int too big to convert",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (\u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m17\u001b[39;49m)\u001b[39m.\u001b[39;49mto_bytes(\u001b[39m2\u001b[39;49m, byteorder\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbig\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m+\u001b[39m (\u001b[39m1024\u001b[39m)\u001b[39m.\u001b[39mto_bytes(\u001b[39m2\u001b[39m, byteorder\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbig\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mOverflowError\u001b[0m: int too big to convert"
     ]
    }
   ],
   "source": [
    "(2**15).to_bytes(2, byteorder='big') + (1024).to_bytes(2, byteorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bytes must be in range(0, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mbytes\u001b[39;49m([\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m, \u001b[39m255\u001b[39;49m, \u001b[39m270\u001b[39;49m])\n",
      "\u001b[0;31mValueError\u001b[0m: bytes must be in range(0, 256)"
     ]
    }
   ],
   "source": [
    "bytes([1,2, 255, 270])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\u2008',\n",
       " '\\u2009',\n",
       " '\\u200a',\n",
       " '\\u200b',\n",
       " '\\u200c',\n",
       " '\\u200d',\n",
       " '\\u200e',\n",
       " '\\u200f',\n",
       " '‐',\n",
       " '‑',\n",
       " '‒',\n",
       " '–',\n",
       " '—',\n",
       " '―',\n",
       " '‖',\n",
       " '‗',\n",
       " '‘',\n",
       " '’',\n",
       " '‚',\n",
       " '‛',\n",
       " '“',\n",
       " '”',\n",
       " '„',\n",
       " '‟',\n",
       " '†',\n",
       " '‡',\n",
       " '•',\n",
       " '‣',\n",
       " '․',\n",
       " '‥',\n",
       " '…',\n",
       " '‧',\n",
       " '\\u2028',\n",
       " '\\u2029',\n",
       " '\\u202a',\n",
       " '\\u202b',\n",
       " '\\u202c',\n",
       " '\\u202d',\n",
       " '\\u202e',\n",
       " '\\u202f',\n",
       " '‰',\n",
       " '‱',\n",
       " '′',\n",
       " '″',\n",
       " '‴',\n",
       " '‵',\n",
       " '‶',\n",
       " '‷',\n",
       " '‸',\n",
       " '‹',\n",
       " '›',\n",
       " '※',\n",
       " '‼',\n",
       " '‽',\n",
       " '‾',\n",
       " '‿',\n",
       " '⁀',\n",
       " '⁁',\n",
       " '⁂',\n",
       " '⁃',\n",
       " '⁄',\n",
       " '⁅',\n",
       " '⁆',\n",
       " '⁇',\n",
       " '⁈',\n",
       " '⁉',\n",
       " '⁊',\n",
       " '⁋',\n",
       " '⁌',\n",
       " '⁍',\n",
       " '⁎',\n",
       " '⁏',\n",
       " '⁐',\n",
       " '⁑',\n",
       " '⁒',\n",
       " '⁓',\n",
       " '⁔',\n",
       " '⁕',\n",
       " '⁖',\n",
       " '⁗',\n",
       " '⁘',\n",
       " '⁙',\n",
       " '⁚',\n",
       " '⁛',\n",
       " '⁜',\n",
       " '⁝',\n",
       " '⁞',\n",
       " '\\u205f',\n",
       " '\\u2060',\n",
       " '\\u2061',\n",
       " '\\u2062',\n",
       " '\\u2063',\n",
       " '\\u2064',\n",
       " '\\u2065',\n",
       " '\\u2066',\n",
       " '\\u2067',\n",
       " '\\u2068',\n",
       " '\\u2069',\n",
       " '\\u206a',\n",
       " '\\u206b']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[chr(i) for i in range(8200, 8300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "PRINTABLE = set(string.printable)\n",
    "\n",
    "set(text) - PRINTABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINTABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation based on https://www.cs.helsinki.fi/u/tpkarkka/publications/jacm05-revised.pdf and https://mailund.dk/posts/skew-python-go/\n",
    "\n",
    "import numpy as np\n",
    "import numba\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "@numba.jit()\n",
    "def merge(x: np.array, SA12: np.array, SA3: np.array) -> np.array:\n",
    "    \"Merge the suffixes in sorted SA12 and SA3.\"\n",
    "    ISA = np.zeros((len(x),), dtype='int')\n",
    "    for i in range(len(SA12)):\n",
    "        ISA[SA12[i]] = i\n",
    "    SA = np.zeros((len(x),), dtype='int')\n",
    "    idx = 0\n",
    "    i, j = 0, 0\n",
    "    while i < len(SA12) and j < len(SA3):\n",
    "        if less(x, SA12[i], SA3[j], ISA):\n",
    "            SA[idx] = SA12[i]\n",
    "            idx += 1\n",
    "            i += 1\n",
    "        else:\n",
    "            SA[idx] = SA3[j]\n",
    "            idx += 1\n",
    "            j += 1\n",
    "    if i < len(SA12):\n",
    "        SA[idx:len(SA)] = SA12[i:]\n",
    "    elif j < len(SA3):\n",
    "        SA[idx:len(SA)] = SA3[j:]\n",
    "    return SA\n",
    "\n",
    "\n",
    "@numba.jit()\n",
    "def u_idx(i: int, m: int) -> int:\n",
    "    \"Map indices in u back to indices in the original string.\"\n",
    "    if i < m:\n",
    "        return 1 + 3 * i\n",
    "    else:\n",
    "        return 2 + 3 * (i - m - 1)\n",
    "\n",
    "\n",
    "@numba.jit()\n",
    "def safe_idx(x: np.array, i: int) -> int:\n",
    "    \"Hack to get zero if we index beyond the end.\"\n",
    "    return 0 if i >= len(x) else x[i]\n",
    "\n",
    "\n",
    "@numba.jit()\n",
    "def symbcount(x: np.array, asize: int) -> np.array:\n",
    "    \"Count how often we see each character in the alphabet.\"\n",
    "    counts = np.zeros((asize,), dtype=\"int\")\n",
    "    for c in x:\n",
    "        counts[c] += 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "@numba.jit()\n",
    "def cumsum(counts: np.array) -> np.array:\n",
    "    \"Compute the cumulative sum from the character count.\"\n",
    "    res = np.zeros((len(counts, )), dtype='int')\n",
    "    acc = 0\n",
    "    for i, k in enumerate(counts):\n",
    "        res[i] = acc\n",
    "        acc += k\n",
    "    return res\n",
    "\n",
    "\n",
    "@numba.jit()\n",
    "def bucket_sort(x: np.array, asize: int,\n",
    "                idx: np.array, offset: int = 0) -> np.array:\n",
    "    \"Sort indices in idx according to x[i + offset].\"\n",
    "    sort_symbs = np.array([safe_idx(x, i + offset) for i in idx])\n",
    "    counts = symbcount(sort_symbs, asize)\n",
    "    buckets = cumsum(counts)\n",
    "    out = np.zeros((len(idx),), dtype='int')\n",
    "    for i in idx:\n",
    "        bucket = safe_idx(x, i + offset)\n",
    "        out[buckets[bucket]] = i\n",
    "        buckets[bucket] += 1\n",
    "    return out\n",
    "\n",
    "\n",
    "@numba.jit()\n",
    "def radix3(x: np.array, asize: int, idx: np.array) -> np.array:\n",
    "    \"Sort indices in idx according to their first three letters in x.\"\n",
    "    idx = bucket_sort(x, asize, idx, 2)\n",
    "    idx = bucket_sort(x, asize, idx, 1)\n",
    "    return bucket_sort(x, asize, idx)\n",
    "\n",
    "\n",
    "@numba.jit()\n",
    "def triplet(x: np.array, i: int) -> Tuple[int, int, int]:\n",
    "    \"Extract the triplet (x[i],x[i+1],x[i+2]).\"\n",
    "    return safe_idx(x, i), safe_idx(x, i + 1), safe_idx(x, i + 2)\n",
    "\n",
    "\n",
    "@numba.jit()\n",
    "def collect_alphabet(x: np.array, idx: np.array) -> Tuple[np.array, int]:\n",
    "    \"Map the triplets starting at idx to a new alphabet.\"\n",
    "    alpha = np.zeros((len(x),), dtype='int')\n",
    "    value = 1\n",
    "    last_trip = -1, -1, -1\n",
    "    for i in idx:\n",
    "        trip = triplet(x, i)\n",
    "        if trip != last_trip:\n",
    "            value += 1\n",
    "            last_trip = trip\n",
    "        alpha[i] = value\n",
    "    return alpha, value - 1\n",
    "\n",
    "\n",
    "@numba.jit()\n",
    "def build_u(x: np.array, alpha: np.array) -> np.array:\n",
    "    \"Construct u string, using 1 as central sentinel.\"\n",
    "    a = np.array([alpha[i] for i in range(1, len(x), 3)] +\n",
    "                 [1] +\n",
    "                 [alpha[i] for i in range(2, len(x), 3)])\n",
    "    return a\n",
    "\n",
    "\n",
    "@numba.jit()\n",
    "def less(x: np.array, i: int, j: int, ISA: np.array) -> bool:\n",
    "    \"Check if x[i:] < x[j:] using the inverse suffix array for SA12.\"\n",
    "    a: int = safe_idx(x, i)\n",
    "    b: int = safe_idx(x, j)\n",
    "    if a < b:\n",
    "        return True\n",
    "    if a > b:\n",
    "        return False\n",
    "    if i % 3 != 0 and j % 3 != 0:\n",
    "        return ISA[i] < ISA[j]\n",
    "    return less(x, i + 1, j + 1, ISA)\n",
    "\n",
    "\n",
    "@numba.jit()\n",
    "def skew_rec(x: np.array, asize: int) -> np.array:\n",
    "    \"skew/DC3 SA construction algorithm.\"\n",
    "\n",
    "    SA12 = np.array([i for i in range(len(x)) if i % 3 != 0])\n",
    "\n",
    "    SA12 = radix3(x, asize, SA12)\n",
    "    new_alpha, new_asize = collect_alphabet(x, SA12)\n",
    "    if new_asize < len(SA12):\n",
    "        # Recursively sort SA12\n",
    "        u = build_u(x, new_alpha)\n",
    "        sa_u = skew_rec(u, new_asize + 2)\n",
    "        m = len(sa_u) // 2\n",
    "        SA12 = np.array([u_idx(i, m) for i in sa_u if i != m])\n",
    "\n",
    "    if len(x) % 3 == 1:\n",
    "        SA3 = np.array([len(x) - 1] + [i - 1 for i in SA12 if i % 3 == 1])\n",
    "    else:\n",
    "        SA3 = np.array([i - 1 for i in SA12 if i % 3 == 1])\n",
    "    SA3 = bucket_sort(x, asize, SA3)\n",
    "    return merge(x, SA12, SA3)\n",
    "\n",
    "\n",
    "def get_suffix_array(x: str) -> np.array:\n",
    "    if \"$\" in x:\n",
    "        raise ValueError('Text should not contain $')\n",
    "    str_to_int = {\n",
    "        \"$\": 0,  # End of strig\n",
    "    }\n",
    "    str_to_int = str_to_int | {\n",
    "        c: n+1\n",
    "        for (n, c) in enumerate(sorted(list(set(x))))\n",
    "    }\n",
    "    return skew_rec(np.array([str_to_int[y] for y in x]), len(str_to_int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sa(sa, t):\n",
    "    for x in sa:\n",
    "        print(t[x:]+t[0:x])\n",
    "    print('-'*10)\n",
    "\n",
    "\n",
    "dna_string = 'AGCTN4ACTGN'\n",
    "suffix_array = get_suffix_array(dna_string)\n",
    "# print_sa(suffix_array, dna_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sort_canon_repr(s):\n",
    "    \"\"\"Returns cononical representation of sort by string s\n",
    "    e.g. [3,1,0,2]\"\"\"\n",
    "    sort_info = [None]*len(s)\n",
    "    for new_place, (c, old_place) in enumerate(sorted([(c, i) for i, c\n",
    "                                                       in enumerate(s)])):\n",
    "        sort_info[old_place] = new_place\n",
    "    return sort_info\n",
    "\n",
    "\n",
    "def apply_permutation(s, perm):\n",
    "    res = [None]*len(s)\n",
    "    for old_place, new_place in enumerate(perm):\n",
    "        res[new_place] = s[old_place]\n",
    "    return res\n",
    "\n",
    "\n",
    "def inverse_permutation(canon_repr):\n",
    "    res = [None]*len(canon_repr)\n",
    "    for old_place, new_place in enumerate(canon_repr):\n",
    "        res[new_place] = old_place\n",
    "    return res\n",
    "\n",
    "\n",
    "ban_bwt = 'а#ннБннБаааа'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bwt & mtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from adaptive import AdaptiveHuffman\n",
    "from itertools import permutations\n",
    "import string\n",
    "SHARP = '#'\n",
    "\n",
    "\n",
    "class BWT:\n",
    "    def encode(t: str):\n",
    "        if SHARP not in t:\n",
    "            raise ValueError(f\"{SHARP}  is not found in text\")\n",
    "        bwt = [None]*len(t)\n",
    "        sa = get_suffix_array(t)\n",
    "        # print_sa(sa, t)\n",
    "        for i in range(len(t)):\n",
    "            bwt[i] = t[sa[i]-1]\n",
    "        return ''.join(bwt)\n",
    "\n",
    "    def decode(bwt: str):\n",
    "        sigma = get_sort_canon_repr(bwt)\n",
    "        inversed_sigma = inverse_permutation(sigma)\n",
    "        res = [None]*len(bwt)\n",
    "        i = bwt.index(SHARP)\n",
    "        index_in_first_col = inversed_sigma[i]\n",
    "        for j, c in enumerate(bwt):\n",
    "            res[j] = bwt[index_in_first_col]\n",
    "            index_in_first_col = inversed_sigma[index_in_first_col]\n",
    "        return ''.join(res)\n",
    "\n",
    "\n",
    "def _shift(alphabet, up, lo):\n",
    "    for i in range(lo, up-1, -1):\n",
    "        alphabet[i+1] = alphabet[i]\n",
    "    return alphabet\n",
    "\n",
    "\n",
    "class mtf:\n",
    "    def get_alphabet():\n",
    "        # return list('#Ban')\n",
    "        return [chr(i) for i in range(ord('z')+1)]\n",
    "\n",
    "    def update_alphabet(alphabet, ind, c):\n",
    "        if ind > 1:\n",
    "            _shift(alphabet, 1, ind-1)\n",
    "            alphabet[1] = c\n",
    "        if ind == 1:\n",
    "            alphabet[1] = alphabet[0]\n",
    "            alphabet[0] = c\n",
    "\n",
    "    def encode(t: str):\n",
    "        alphabet = mtf.get_alphabet()\n",
    "        diff = set(t)-set(alphabet)\n",
    "        if diff:\n",
    "            raise ValueError(\n",
    "                f'Found chars in text that are not presented in alphabet: {diff}')\n",
    "        res = []\n",
    "        for c in t:\n",
    "            ind = alphabet.index(c)\n",
    "            res.append(ind)\n",
    "            mtf.update_alphabet(alphabet, ind, c)\n",
    "        # print(f\"mtf res max & min: {max(res), min(res)}\")\n",
    "        return res\n",
    "\n",
    "    def decode(encoded):  # list of indecies\n",
    "        alphabet = mtf.get_alphabet()\n",
    "        res = []\n",
    "        diff = set(encoded) - set(range(len(alphabet)))\n",
    "        if diff:\n",
    "            raise ValueError(f\"Found wrong indecies in encoded by mtf: {diff}\")\n",
    "        for ind in encoded:\n",
    "            c = alphabet[ind]\n",
    "            res.append(c)\n",
    "            mtf.update_alphabet(alphabet, ind, c)\n",
    "        return ''.join(res)\n",
    "\n",
    "\n",
    "class rle:\n",
    "    def encode(ar):\n",
    "        res = []\n",
    "        cntrs = []\n",
    "        prev_is_zero = False\n",
    "        for x in ar:\n",
    "            if x != 0:\n",
    "                res.append(x)\n",
    "                prev_is_zero = False\n",
    "                continue\n",
    "            if prev_is_zero:\n",
    "                cntrs[-1] += 1\n",
    "            else:\n",
    "                res.append(0)\n",
    "                cntrs.append(1)\n",
    "            prev_is_zero = True\n",
    "        # print(f\"max in cntrs = {max(cntrs)}\")\n",
    "        return res, cntrs\n",
    "\n",
    "    def decode(rle_encoded, cntrs):\n",
    "        res = []\n",
    "        for x in rle_encoded:\n",
    "            if x != 0:\n",
    "                res.append(x)\n",
    "                continue\n",
    "            res.extend([0]*cntrs.pop(0))\n",
    "        return res\n",
    "\n",
    "\n",
    "def random_subtext(text, length):\n",
    "    i = random.randrange(0, len(text) - length - 2)\n",
    "    return text[i:i+length]\n",
    "\n",
    "\n",
    "def randomword(length):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(length))\n",
    "\n",
    "\n",
    "def test_bwt_encode_decode():\n",
    "    for i in range(1000):\n",
    "        w = random_subtext(text, 1000)+SHARP\n",
    "        # print(w)\n",
    "        assert BWT.decode(BWT.encode(w)) == w\n",
    "\n",
    "\n",
    "def test_mtf():\n",
    "    for i in range(1000):\n",
    "        w = random_subtext(text, 1000)+SHARP\n",
    "        # print(w)\n",
    "        assert mtf.decode(mtf.encode(w)) == w\n",
    "\n",
    "\n",
    "def test_rle():\n",
    "    for i in range(100):\n",
    "        w = random_subtext(text, 1000)+SHARP\n",
    "        ar = mtf.encode(BWT.encode(w))\n",
    "        # print(ar)\n",
    "        assert rle.decode(*rle.encode(ar)) == ar\n",
    "\n",
    "\n",
    "# test_bwt_encode_decode()\n",
    "# test_mtf()\n",
    "# test_rle()\n",
    "\n",
    "\n",
    "def test_permutation():\n",
    "    a = list('abbced')\n",
    "    for perm in list(permutations(list(range(len(a)))))[:100]:\n",
    "        assert a == apply_permutation(\n",
    "            apply_permutation(a, perm), inverse_permutation(perm))\n",
    "\n",
    "\n",
    "# test_permutation()\n",
    "\n",
    "\n",
    "class Huffman:\n",
    "    def encode(l: list):\n",
    "        ada_huff = AdaptiveHuffman(bytes(l))\n",
    "        return ada_huff.encode()\n",
    "\n",
    "    def decode(code: bitarray):\n",
    "        add_huff_decoder = AdaptiveHuffman(code)\n",
    "        return add_huff_decoder.decode()\n",
    "\n",
    "\n",
    "def test_huffman():\n",
    "    for i in range(10):\n",
    "        l = [random.randint(3, 9) for _ in range(10)]\n",
    "        assert l == Huffman.decode(Huffman.encode(l))\n",
    "\n",
    "# test_huffman()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bitarray('00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001011')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gamma_code(number_bits):\n",
    "    number = int(''.join(map(str, number_bits)), 2)\n",
    "    # number += 1  # кодируем число на 1 больше чтобы могли подавать нули\n",
    "    i = math.floor(math.log(number, 2))\n",
    "    return bitarray([0]*i + [int(c) for c in \"{0:b}\".format(number)[-(i+1):]])\n",
    "\n",
    "\n",
    "def delta_code(number_bits):\n",
    "    number = int(''.join(map(str, number_bits)), 2)\n",
    "    i = math.floor(math.log(number, 2))\n",
    "    try:\n",
    "        diap = gamma_code(\"{0:b}\".format(i+1))\n",
    "    except:\n",
    "        raise ValueError(i)\n",
    "    return diap+bitarray([int(c) for c in \"{0:b}\".format(number)[-(i+1):]])\n",
    "\n",
    "\n",
    "def list_int_to(l, func_code):\n",
    "    res = bitarray()\n",
    "    for c in l:\n",
    "        res.extend(func_code(\"{0:b}\".format(c)))\n",
    "    return res\n",
    "\n",
    "\n",
    "def gamma_to_list_int(ar: bitarray):\n",
    "    j = 0\n",
    "    res = []\n",
    "    zeros_cnt = 0\n",
    "    while j < len(ar):\n",
    "        if ar[j] == 0:\n",
    "            zeros_cnt += 1\n",
    "            j += 1\n",
    "            continue\n",
    "        number_bits = ar[j:j+zeros_cnt+1]\n",
    "        number = int(number_bits.to01(), 2)\n",
    "        res.append(number)\n",
    "        j = j + zeros_cnt+1\n",
    "        zeros_cnt = 0\n",
    "    return res\n",
    "\n",
    "\n",
    "def list_int_to_gamma(l):\n",
    "    res = bitarray()\n",
    "    for c in l:\n",
    "        gamma_coded = gamma_code(\"{0:b}\".format(c))\n",
    "        res.extend(gamma_coded)\n",
    "    return res\n",
    "\n",
    "\n",
    "def overflow_code(x, scheme):\n",
    "    \"\"\"scheme == [4, 8, 8] ~ 4 + 8 + 8\"\"\"\n",
    "    exp = scheme[0]\n",
    "    upper_bound = 2**exp - 2\n",
    "    if 0 <= x <= upper_bound:\n",
    "        return \"{0:b}\".format(x).rjust(exp, '0')\n",
    "    ones_cnt = exp  # кол-во единиц перед началом числа\n",
    "    for exp in scheme[1:]:\n",
    "        prev_upper_bound = upper_bound\n",
    "        upper_bound = upper_bound + 2**exp - 1\n",
    "        if x <= upper_bound:\n",
    "            return '1'*ones_cnt + \"{0:b}\".format(x-(prev_upper_bound+1)).rjust(exp, '0')\n",
    "        ones_cnt += exp\n",
    "    raise ValueError(f\"Scheme {scheme} is not enough to code {x}\")\n",
    "\n",
    "\n",
    "def overflow_array(l):\n",
    "    res = bitarray()\n",
    "    for x in l:\n",
    "        res.extend(overflow_code(x, [2, 4, 16]))\n",
    "    return res\n",
    "\n",
    "\n",
    "HEADER_SIZE = 128\n",
    "\n",
    "\n",
    "def get_header(x):\n",
    "    \"\"\"x - length of huffman compressed data\"\"\"\n",
    "    return bitarray(\"{0:b}\".format(x).rjust(HEADER_SIZE, '0'))\n",
    "\n",
    "\n",
    "def test_gamma():\n",
    "    for i in range(10):\n",
    "        l = [random.randint(3, 9) for _ in range(100)]\n",
    "        assert l == gamma_to_list_int(list_int_to_gamma(l))\n",
    "\n",
    "\n",
    "test_gamma()\n",
    "get_header(11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"11\".rjust(1, '0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rle_compressed, cntrs = rle.encode(mtf.encode(BWT.encode(part_text+SHARP)))\n",
    "from functools import partial\n",
    "global_cntrs = None\n",
    "global_rle_compressed = None\n",
    "global_mtf_encoded = None\n",
    "global_huffman_compressed = None\n",
    "global_huffman_len = None\n",
    "global_cntrs_compressed = None\n",
    "\n",
    "\n",
    "class Archiver:\n",
    "    def encode(text):\n",
    "        global global_cntrs\n",
    "        global global_cntrs_compressed\n",
    "        global global_rle_compressed\n",
    "        global global_mtf_encoded\n",
    "        global global_huffman_compressed\n",
    "        global global_huffman_len\n",
    "        if '$' in text:\n",
    "            raise ValueError('Text should not contain $')\n",
    "        if '#' in text:\n",
    "            raise ValueError('Text should not contain #')\n",
    "        unprintable = set(text)-PRINTABLE\n",
    "        if unprintable:\n",
    "            raise ValueError(f\"Found unsupported symbols: {unprintable}\")\n",
    "        t = text + SHARP\n",
    "        mtf_encoded = mtf.encode(BWT.encode(t))\n",
    "        global_mtf_encoded = mtf_encoded\n",
    "        global_mtf_encoded = mtf_encoded\n",
    "        rle_compressed, cntrs = rle.encode(mtf_encoded)\n",
    "        global_rle_compressed = rle_compressed\n",
    "        huffman_compressed = Huffman.encode(rle_compressed)\n",
    "        global_huffman_compressed = huffman_compressed\n",
    "        huffman_len = len(huffman_compressed)\n",
    "        global_huffman_len = huffman_len\n",
    "        header = get_header(huffman_len)\n",
    "        cntrs_compressed = list_int_to_gamma(cntrs)\n",
    "        global_cntrs_compressed = cntrs_compressed\n",
    "        global_cntrs = cntrs\n",
    "        return header+huffman_compressed+cntrs_compressed\n",
    "\n",
    "    def decode(ar: bitarray):\n",
    "        header = ar[:HEADER_SIZE]\n",
    "        huffman_len = int(header.to01(), 2)\n",
    "        # assert huffman_len == global_huffman_len, f\"{huffman_len} {global_huffman_len}\"\n",
    "        huffman_compressed = ar[HEADER_SIZE:HEADER_SIZE+huffman_len]\n",
    "        # assert huffman_compressed == global_huffman_compressed\n",
    "        cntrs_compressed = ar[HEADER_SIZE+huffman_len:]\n",
    "        # assert cntrs_compressed == global_cntrs_compressed\n",
    "        cntrs = gamma_to_list_int(cntrs_compressed)\n",
    "        rle_compressed = Huffman.decode(huffman_compressed)\n",
    "        # assert rle_compressed == global_rle_compressed\n",
    "        mtf_encoded = rle.decode(rle_compressed, cntrs)\n",
    "        # assert mtf_encoded == global_mtf_encoded\n",
    "        return BWT.decode(mtf.decode(mtf_encoded))[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_archiver():\n",
    "    for i in range(10):\n",
    "        w = random_subtext(text, 1000)  # +SHARP\n",
    "        # print(w)\n",
    "        assert w == Archiver.decode(Archiver.encode(w))\n",
    "\n",
    "\n",
    "test_archiver()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tiny_text \u001b[39m=\u001b[39m text\u001b[39m#random_subtext(text, 100_000)#text[:10_000]#'ababcabca'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m bitar \u001b[39m=\u001b[39m Archiver\u001b[39m.\u001b[39;49mencode(tiny_text)\n\u001b[1;32m      3\u001b[0m decompressed \u001b[39m=\u001b[39m Archiver\u001b[39m.\u001b[39mdecode(bitar)\n\u001b[1;32m      4\u001b[0m \u001b[39m# print(decompressed)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# cntrs\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[103], line 32\u001b[0m, in \u001b[0;36mArchiver.encode\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     30\u001b[0m rle_compressed, cntrs \u001b[39m=\u001b[39m rle\u001b[39m.\u001b[39mencode(mtf_encoded)\n\u001b[1;32m     31\u001b[0m global_rle_compressed \u001b[39m=\u001b[39m rle_compressed\n\u001b[0;32m---> 32\u001b[0m huffman_compressed \u001b[39m=\u001b[39m Huffman\u001b[39m.\u001b[39;49mencode(rle_compressed)\n\u001b[1;32m     33\u001b[0m global_huffman_compressed \u001b[39m=\u001b[39m huffman_compressed\n\u001b[1;32m     34\u001b[0m huffman_len \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(huffman_compressed)\n",
      "Cell \u001b[0;32mIn[100], line 157\u001b[0m, in \u001b[0;36mHuffman.encode\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(l: \u001b[39mlist\u001b[39m):\n\u001b[1;32m    156\u001b[0m     ada_huff \u001b[39m=\u001b[39m AdaptiveHuffman(\u001b[39mbytes\u001b[39m(l))\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m ada_huff\u001b[39m.\u001b[39;49mencode()\n",
      "File \u001b[0;32m~/Data/1Education/KASD/compressor/adaptive.py:270\u001b[0m, in \u001b[0;36mAdaptiveHuffman.encode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mfor\u001b[39;00m symbol \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbyte_seq:\n\u001b[1;32m    269\u001b[0m     fixed_code \u001b[39m=\u001b[39m encode_fixed_code(symbol)\n\u001b[0;32m--> 270\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree\u001b[39m.\u001b[39;49msearch(fixed_code)\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m result[\u001b[39m'\u001b[39m\u001b[39mfirst_appearance\u001b[39m\u001b[39m'\u001b[39m]:  \u001b[39m# ~symbol is not presented in tree yet\u001b[39;00m\n\u001b[1;32m    272\u001b[0m         code\u001b[39m.\u001b[39mextend(result[\u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m])  \u001b[39m# send code of NYT\u001b[39;00m\n",
      "File \u001b[0;32m~/Data/1Education/KASD/compressor/adaptive.py:127\u001b[0m, in \u001b[0;36mTree.search\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[39mif\u001b[39;00m current\u001b[39m.\u001b[39mleft:\n\u001b[1;32m    126\u001b[0m         current\u001b[39m.\u001b[39mleft\u001b[39m.\u001b[39mcode \u001b[39m=\u001b[39m current\u001b[39m.\u001b[39mcode \u001b[39m+\u001b[39m [\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 127\u001b[0m         stack\u001b[39m.\u001b[39;49mappend(current\u001b[39m.\u001b[39;49mleft)\n\u001b[1;32m    128\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfirst_appearance\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m: nytcode}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tiny_text = text  # random_subtext(text, 100_000)#text[:10_000]#'ababcabca'\n",
    "bitar = Archiver.encode(tiny_text)\n",
    "decompressed = Archiver.decode(bitar)\n",
    "# print(decompressed)\n",
    "# cntrs\n",
    "(len(bitar)/8)/len(tiny_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
